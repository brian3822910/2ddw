                            开发上遇到的问题
1.laravel5.5打上以后对_ide_helper.php里面的内容命令不太感冒里面没有useFiles函数所以不能自定义建立日志文件，所以有时还是使用
use Monolog\Handler\StreamHandler;
use Monolog\Logger;
   $log = new Logger('elascre');

        $log->pushHandler(
            new StreamHandler(
                storage_path('logs/'.date('Ymd').'.log'), 
                Logger::INFO
            )
        );

        $log->addInfo("{$date} —— 调试：{$info}");
这种方法来写日志最好，我试过在5.5以下或以上都能使用。
2.最新的laravel6.0要这样才能跑PHP >= 7.2.0
3.数据库的拆份打算用mycat还是FEDERATED引擎，还是阿里云的那一种方法来？
4.数据库的拆份能否用nosql(包括 HBase、Redis、MongoDB、Couchbase、LevelDB)来解决?	
  总结一下：
	1） Redis其实只适合作为缓存，而不是数据库或是存储。它的持久化方式适用于救救急啥的，不太适合当作一个普通功能来用。对于这个版本的Redis，不建议使用任何的持久化方式。否则到时候可能会死的比较难看。说白了，期望Redis是memcached的升级版，带有各种数据结构，但是不要期望Redis来和Mongodb/Kt等来比。
	2） 对于VM其实也是不建议开启，虽然开启VM可以让Redis保存比内存更多的数据，但是如果冷热数据不是很明显的话性能会非常差（我的测试都是随机查询Key，冷热不明显）。当然，对于冷热明显的情况下可以设置200% - 400%的内存作为VM空间，也不建议设置10倍的内存空间作为VM（像我的配置一样）。
	3） ServiceStack.Redis客户端好像有几个Bug，首先RedisTypedClient的Dispose居然没有实现，应该是要调用client.Dispose()，其次RedisNativeClient的Info属性不是每次都获取最新值的，第三PooledRedisClientManager的WritePoolIndex和ReadPoolIndex只看到加没看到减的地方，也不知道这是干啥的，其实每次都取第一个不是Active的Client就可以了，PooledRedisClientManager也没有把超时使用的Active的Client强制回收（避免使用的时候忘记Dispose占用过多的连接）。
5.进行了一下Mongodb亿级数据量的性能测试
总结一下，发现几个问题需要值得注意：
1） 在数据量很大的情况下，对服务进行重启，那么服务启动的初始化阶段，虽然可以接受数据的查询和修改，但是此时性能很差，因为mongodb会不断把数据从磁盘换入内存，此时的IO压力非常大。
2） 在数据量很大的情况下，如果服务没有正常关闭，那么Mongodb启动修复数据库的时间非常可观，在1.8中退出的-dur貌似可以解决这个问题，据官方说对读取没影响，写入速度会稍稍降低，有空我也会再进行下测试。
3） 在使用Sharding的时候，Mongodb时不时会对数据拆分搬迁，这个时候性能下降很厉害，虽然从测试图中看不出（因为我每一次测试都会测试比较多的迭代次数），但是我在实际观察中可以发现，在搬迁数据的时候每秒插入性能可能会低到几百条。其实我觉得能手动切分数据库就手动切分或者手动做历史库，不要依赖这种自动化的Sharding，因为一开始数据就放到正确的位置比分隔再搬迁效率不知道高多少。个人认为Mongodb单数据库存储不超过1亿的数据比较合适，再大还是手动分库吧。
4） 对于数据的插入，如果使用多线程并不会带来性能的提高，反而还会下降一点性能（并且可以在http接口上看到，有大量的线程处于等待）。
5） 在整个测试过程中，批量插入的时候遇到过几次连接被远程计算机关闭的错误，怀疑是有的时候Mongodb不稳定关闭了连接，或是官方的C#客户端有BUG，但是也仅仅是在数据量特别大的时候遇到几次。
6.发现了读取力报用户信息时的api接口有时因为数据库里面的用户信息被删除了产生了报错信息出来，所以这个还是要加上容错的处理，避免出现报错的信息出来。